{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c12c379",
   "metadata": {},
   "source": [
    "# NLP Tutorial:Text Classification USing Gensim Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee01014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# pip install spacy-download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1bd1a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement python (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for python\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install python spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61c03bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import gensim\n",
    "from spacy_download import load_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19008a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34edbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.2.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85e5ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to read local cache '/home/sangramdh/gensim-data/information.json' during fallback, connect to the Internet and retry",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/downloader.py:219\u001b[0m, in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# We need io.open here because Py2 open doesn't support encoding keyword\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(fin)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sangramdh/gensim-data/information.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/downloader.py:268\u001b[0m, in \u001b[0;36minfo\u001b[0;34m(name, show_only_latest, name_only)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, show_only_latest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124;03m\"\"\"Provide the information related to model/dataset.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     information \u001b[38;5;241m=\u001b[39m \u001b[43m_load_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         corpora \u001b[38;5;241m=\u001b[39m information[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpora\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/downloader.py:222\u001b[0m, in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(fin)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munable to read local cache \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m during fallback, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnect to the Internet and retry\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m cache_path\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: unable to read local cache '/home/sangramdh/gensim-data/information.json' during fallback, connect to the Internet and retry"
     ]
    }
   ],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf66897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset with name \"cyber.csv\" and store it in a variable df\n",
    "cyber = pd.read_csv(\"/home/sangramdh/jupyter/NLP/text_classification/data/cybersecurity_tweets.csv\", usecols=['text','label'])\n",
    "\n",
    "#print the shape of dataframe\n",
    "print(cyber.shape)\n",
    "\n",
    "#print top 5 rows\n",
    "cyber.head(555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6183480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read the dataset with name \"non_cyber.csv\" and store it in a variable df\n",
    "non_cyber = pd.read_csv(\"/home/sangramdh/jupyter/NLP/text_classification/data/not_cybersecurity_tweets.csv\", usecols=['text', 'label'])\n",
    "\n",
    "#print the shape of dataframe\n",
    "print(non_cyber.shape)\n",
    "\n",
    "#print top 5 rows\n",
    "non_cyber.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390eff6",
   "metadata": {},
   "source": [
    "### Check uniques values in \"label\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a30b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber.label.unique() # for cyber dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eed01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac42176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cyber.label.unique()) # check count how many uniques are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e63b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cyber.label.unique() # check for non_cyber dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cced021",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_cyber.label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565665f8",
   "metadata": {},
   "source": [
    "#### I'm getting here at label column in both the dataset, some unique which is not good.\n",
    "we need to clean that so that we can move forword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber['label'] = cyber.label.replace(cyber.label.unique(), 1) # replacing the value for cyber dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber_labeled = cyber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1032d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cyber_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d542a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(cyber_labeled.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fe193",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cyber['label'] = non_cyber.label.replace(non_cyber.label.unique(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6da4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cyber_labeled = non_cyber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ed0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cyber_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6acb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_cyber_labeled.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the distribution of labels \n",
    "print(non_cyber_labeled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce255201",
   "metadata": {},
   "source": [
    "### concanet the data frame => cyber_labeled + non_cyber_labeled = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6736ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# concatenating df1 and df2 along rows\n",
    "data = pd.concat([cyber_labeled, non_cyber_labeled], axis=0)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46d46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the distribution of labels \n",
    "print(data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e0222",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03303e8",
   "metadata": {},
   "source": [
    "#### ```Now we have propely labeled data we can move forward for making vectors```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcb8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4291c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1e249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07510988",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.mean([wv_good, wv_great],axis=0) # I was checking real mean is similar to \"get_mean_vactor\" or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_good[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38164bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_great[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8968e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3299553",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = wv.get_mean_vector([\"good\", \"great\"],pre_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30883c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a884062",
   "metadata": {},
   "source": [
    "### Preprocess and make them a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s\\']', ' ', text)\n",
    "    text = re.sub(r'[- \\n]+', ' ', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91228ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2180754472.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python3 -m spacy download en_core_web_sm\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacff444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 12:32:56.442787: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-28 12:32:57.185630: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-28 12:32:57.185719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-28 12:32:57.185731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-28 12:32:57.938000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-28 12:32:57.938037: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-28 12:32:57.938057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (GaribaITServices): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_lg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/util.py:439\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load_spacy(\"en_core_web_lg\", exclude=[\"parser\", \"tagger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_vectorize(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "    return wv.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = preprocess_and_vectorize(\"Don't worry if you don't understand\")\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this query takes few minutes, so go get some walk :)\n",
    "\n",
    "df['vector'] = df['Text'].apply(lambda text: preprocess_and_vectorize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d56149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a632ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786a1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06828b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877ed24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc69902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7cedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95363132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdeb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf21b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847951f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3460b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03cb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed8b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416debf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cc171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc9b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8158a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef0737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03fe1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685bbe05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecb3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3104a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad778ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042fde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835e1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8191fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0f5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c965a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f273fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d705a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d9bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053c4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d675c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4a5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46126d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72269aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526945dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cb922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb074596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8439802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738a956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ab40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bccc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ad810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5672ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdeef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1b212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122fcf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a171034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbfbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.vector.values, \n",
    "    df.label_num, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.label_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train before reshaping: \", X_train.shape)\n",
    "print(\"Shape of X_test before reshaping: \", X_test.shape)\n",
    "\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d =  np.stack(X_test)\n",
    "\n",
    "print(\"Shape of X_train after reshaping: \", X_train_2d.shape)\n",
    "print(\"Shape of X_test after reshaping: \", X_test_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news = [\n",
    "    \"Michigan governor denies misleading U.S. House on Flint water (Reuters) - Michigan Governor Rick Snyder denied Thursday that he had misled a U.S. House of Representatives committee last year over testimony on Flintâ€™s water crisis after lawmakers asked if his testimony had been contradicted by a witness in a court hearing. The House Oversight and Government Reform Committee wrote Snyder earlier Thursday asking him about published reports that one of his aides, Harvey Hollins, testified in a court hearing last week in Michigan that he had notified Snyder of an outbreak of Legionnairesâ€™ disease linked to the Flint water crisis in December 2015, rather than 2016 as Snyder had testified. â€œMy testimony was truthful and I stand by it,â€ Snyder told the committee in a letter, adding that his office has provided tens of thousands of pages of records to the committee and would continue to cooperate fully.  Last week, prosecutors in Michigan said Dr. Eden Wells, the stateâ€™s chief medical executive who already faced lesser charges, would become the sixth current or former official to face involuntary manslaughter charges in connection with the crisis. The charges stem from more than 80 cases of Legionnairesâ€™ disease and at least 12 deaths that were believed to be linked to the water in Flint after the city switched its source from Lake Huron to the Flint River in April 2014. Wells was among six current and former Michigan and Flint officials charged in June. The other five, including Michigan Health and Human Services Director Nick Lyon, were charged at the time with involuntary manslaughter\",\n",
    "    \" WATCH: Fox News Host Loses Her Sh*t, Says Investigating Russia For Hacking Our Election Is Unpatriotic This woman is insane.In an incredibly disrespectful rant against President Obama and anyone else who supports investigating Russian interference in our election, Fox News host Jeanine Pirro said that anybody who is against Donald Trump is anti-American. Look, it s time to take sides,  she began.\",\n",
    "    \" Sarah Palin Celebrates After White Man Who Pulled Gun On Black Protesters Goes Unpunished (VIDEO) Sarah Palin, one of the nigh-innumerable  deplorables  in Donald Trump s  basket,  almost outdid herself in terms of horribleness on Friday.\"\n",
    "]\n",
    "\n",
    "test_news_vectors = [preprocess_and_vectorize(n) for n in test_news]\n",
    "clf.predict(test_news_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally print the confusion matrix for the best model (GradientBoostingClassifier)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34735629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac716bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72e25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e28111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e488a359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049dbd08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb4472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
